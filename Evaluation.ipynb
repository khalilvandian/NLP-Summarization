{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"V28"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0fc028aa93e34005bf3b4d6b4c2e0e32":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b91d257db854215b3ccbb466c0aa84d","IPY_MODEL_8f7889c6a73643e2ab38e088863fd201","IPY_MODEL_66cf53e8824f49daa82c51b54dc5ee09"],"layout":"IPY_MODEL_1a2194943b8046c8aeefe8b7655458e0"}},"4b91d257db854215b3ccbb466c0aa84d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e195bb7c16d944acad485baaf13552e8","placeholder":"​","style":"IPY_MODEL_31ffa63cc4b54a6b88a06d5b7de85ea9","value":"  0%"}},"8f7889c6a73643e2ab38e088863fd201":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_5454094b3e774609bf89c9dd212d8e3b","max":354,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab8592b7855e4a90a797481ffa77a630","value":0}},"66cf53e8824f49daa82c51b54dc5ee09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b5e6911821e4ff18898401ed45a1829","placeholder":"​","style":"IPY_MODEL_19d324a3d4724debb4a9c1cb220c9a34","value":" 0/354 [00:17&lt;?, ?it/s]"}},"1a2194943b8046c8aeefe8b7655458e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e195bb7c16d944acad485baaf13552e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31ffa63cc4b54a6b88a06d5b7de85ea9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5454094b3e774609bf89c9dd212d8e3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab8592b7855e4a90a797481ffa77a630":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b5e6911821e4ff18898401ed45a1829":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19d324a3d4724debb4a9c1cb220c9a34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12218606,"sourceType":"datasetVersion","datasetId":7697814}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"9733de2c","cell_type":"markdown","source":"# Prompting flan-T5-base","metadata":{"id":"9733de2c"}},{"id":"K0q-D7U1vL7d","cell_type":"code","source":"## Config\nrandom_seed = 100\ndata_path = \"/kaggle/working/\"","metadata":{"id":"K0q-D7U1vL7d","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T13:59:56.311067Z","iopub.execute_input":"2025-06-19T13:59:56.311685Z","iopub.status.idle":"2025-06-19T13:59:56.317633Z","shell.execute_reply.started":"2025-06-19T13:59:56.311660Z","shell.execute_reply":"2025-06-19T13:59:56.316872Z"}},"outputs":[],"execution_count":1},{"id":"d17589d5","cell_type":"code","source":"%%capture\n!pip install -U datasets\n!pip install transformers datasets evaluate rouge_score --quiet\n!pip uninstall keras -y\n!pip install keras==2.11\n!pip install bert_score","metadata":{"id":"d17589d5","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T13:59:56.318570Z","iopub.execute_input":"2025-06-19T13:59:56.318770Z","iopub.status.idle":"2025-06-19T14:01:35.688407Z","shell.execute_reply.started":"2025-06-19T13:59:56.318755Z","shell.execute_reply":"2025-06-19T14:01:35.687596Z"}},"outputs":[],"execution_count":2},{"id":"dZnDJJJSJ-BC","cell_type":"code","source":"import evaluate\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nimport torch\nimport pandas as pd\nfrom bert_score import score\nimport pickle\nimport os","metadata":{"id":"dZnDJJJSJ-BC","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T14:01:35.689858Z","iopub.execute_input":"2025-06-19T14:01:35.690083Z","iopub.status.idle":"2025-06-19T14:02:07.076084Z","shell.execute_reply.started":"2025-06-19T14:01:35.690061Z","shell.execute_reply":"2025-06-19T14:02:07.075509Z"}},"outputs":[{"name":"stderr","text":"2025-06-19 14:01:48.800161: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750341708.990997      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750341709.044044      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"id":"DSBfAOyAueZ8","cell_type":"markdown","source":"## Load Data and Model","metadata":{"id":"DSBfAOyAueZ8"}},{"id":"ca2bae17","cell_type":"code","source":"# Full dataset (split included)\ndataset = load_dataset(\"EdinburghNLP/xsum\")","metadata":{"id":"ca2bae17","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T14:02:07.076695Z","iopub.execute_input":"2025-06-19T14:02:07.077143Z","iopub.status.idle":"2025-06-19T14:02:14.996177Z","shell.execute_reply.started":"2025-06-19T14:02:07.077124Z","shell.execute_reply":"2025-06-19T14:02:14.995696Z"},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1c6f3b9f-5c7f-4e97-b3db-2ff830a86ea9"},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/6.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fad6b670b1b4934bb25d7d333dadeda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"xsum.py:   0%|          | 0.00/5.76k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"537b6059b3464aa691076e5f9cb5d7b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/304M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0067095de91749bfb83fc387c3cbf065"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/16.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"285d64f564f8451f8ea9a2ae8a22b289"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/17.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2369bb2fc9f04cb29a7e6d4c0a02cbdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/204045 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"740675bcdbd74725956354e10be11ecb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11332 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8bc75615f1449ed9f7a28f4ca47288e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11334 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ff1aa53d0f74becbafbe38dd34e50b6"}},"metadata":{}}],"execution_count":4},{"id":"PqFJfBEPwVK8","cell_type":"code","source":"# Few-shot examples from training set\ntrain_examples = dataset[\"train\"].select(range(2))\n\n# Sample a subset of the test set for evaluation\ntest_sample = dataset[\"test\"]\nreferences = [example[\"summary\"] for example in test_sample]","metadata":{"id":"PqFJfBEPwVK8","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T14:02:14.997724Z","iopub.execute_input":"2025-06-19T14:02:14.997946Z","iopub.status.idle":"2025-06-19T14:02:15.326921Z","shell.execute_reply.started":"2025-06-19T14:02:14.997928Z","shell.execute_reply":"2025-06-19T14:02:15.326346Z"}},"outputs":[],"execution_count":5},{"id":"713cbb86","cell_type":"code","source":"model_name = \"google/flan-t5-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=2024)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"id":"713cbb86","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T14:02:15.327606Z","iopub.execute_input":"2025-06-19T14:02:15.327851Z","iopub.status.idle":"2025-06-19T14:02:26.069505Z","shell.execute_reply.started":"2025-06-19T14:02:15.327834Z","shell.execute_reply":"2025-06-19T14:02:26.068697Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6e92c7aece34903911ab0784dff3b13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab25953c898847cab186eca78317cf93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"280ff669a2a84b298ef87fe231b8f485"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51714ac8e3604b6eb6d0027900d8394a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be654f126e08473c82352e3c3c7b5fb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"717dec60b3314a23a499381c1d89f671"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf252cee6b5a4b809f58ef176769f950"}},"metadata":{}}],"execution_count":6},{"id":"P0Q9IVuufRQw","cell_type":"markdown","source":"## Zero-Shot, One-Shot and Few-Shot Prompts","metadata":{"id":"P0Q9IVuufRQw"}},{"id":"_CmaGiOifi6Y","cell_type":"code","source":"def build_zero_shot_prompt(doc):\n    \"\"\"Builds a zero-shot prompt.\"\"\"\n    prompt_template = \"Summarize the input text.\\n\\n ### INPUT TEXT\\nDocument:{}\\nSummary:[Fill the summary]\"\n    return prompt_template.format(doc)\n\ndef build_one_shot_prompt(doc, train_example):\n    \"\"\"Builds a one-shot prompt with one example.\"\"\"\n    prompt = \"\"\n    prompt += \"Task: Summarize the input text. An example is provided below. \\n\"\n    prompt += f\"### EXAMPLE:\\nDocument: {train_example['document'].strip()}\\nSummary: {train_example['summary'].strip()}\\n\\n\"\n    prompt += f\"### INPUT TEXT:\\nDocument: {doc.strip()}\\nSummary:[Fill the summary]\"\n    return prompt\n\ndef build_few_shot_prompt(doc, few_shots):\n    \"\"\"Builds a few-shot prompt with multiple examples.\"\"\"\n    prompt = \"\"\n    prompt += \"Task: Summarize the input text. Examples are provided below. \\n\"\n    for ex in few_shots:\n        prompt += f\"### EXAMPLE:\\nDocument: {ex['document'].strip()}\\nSummary: {ex['summary'].strip()}\\n\\n\"\n    prompt += f\"### INPUT TEXT:\\nDocument: {doc.strip()}\\nSummary:[Fill the summary]\"\n    return prompt","metadata":{"id":"_CmaGiOifi6Y","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T14:02:26.070321Z","iopub.execute_input":"2025-06-19T14:02:26.070620Z","iopub.status.idle":"2025-06-19T14:02:26.077075Z","shell.execute_reply.started":"2025-06-19T14:02:26.070595Z","shell.execute_reply":"2025-06-19T14:02:26.076525Z"}},"outputs":[],"execution_count":7},{"id":"kdyt0Ho0gY_l","cell_type":"code","source":"# document = test_sample[0][\"document\"]\n\n# zero_shot_prompts = [build_zero_shot_prompt(document[\"document\"]) for document in test_sample]\n# one_shot_prompts = [build_one_shot_prompt(document[\"document\"], train_examples[0]) for document in test_sample]\n# few_shot_prompts = [build_few_shot_prompt(document[\"document\"], train_examples) for document in test_sample]","metadata":{"id":"kdyt0Ho0gY_l","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T14:02:26.077789Z","iopub.execute_input":"2025-06-19T14:02:26.078043Z","iopub.status.idle":"2025-06-19T14:02:27.479239Z","shell.execute_reply.started":"2025-06-19T14:02:26.078012Z","shell.execute_reply":"2025-06-19T14:02:27.478339Z"}},"outputs":[],"execution_count":8},{"id":"6yyqabZMQJuw","cell_type":"code","source":"zero_shot_prompts = []\nfor document in test_sample:\n    prompt = build_zero_shot_prompt(document[\"document\"])\n    zero_shot_prompts.append(prompt)\n\none_shot_prompts = []\nfor document in test_sample:\n    prompt = build_one_shot_prompt(document[\"document\"], train_examples[0])\n    one_shot_prompts.append(prompt)\n\n# few_shot_prompts = []\n# for document in test_sample:\n#     prompt = build_few_shot_prompt(document[\"document\"], train_examples)\n#     few_shot_prompts.append(prompt)","metadata":{"id":"6yyqabZMQJuw","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T14:02:27.480194Z","iopub.execute_input":"2025-06-19T14:02:27.480502Z","iopub.status.idle":"2025-06-19T14:02:29.656464Z","shell.execute_reply.started":"2025-06-19T14:02:27.480479Z","shell.execute_reply":"2025-06-19T14:02:29.655643Z"}},"outputs":[],"execution_count":9},{"id":"342c7578-3bb3-4f68-a084-bfa7f98bcf4f","cell_type":"code","source":"few_shot_prompts = []\nfor document in test_sample:\n    prompt = build_few_shot_prompt(document[\"document\"], train_examples)\n    few_shot_prompts.append(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T17:12:26.938749Z","iopub.execute_input":"2025-06-19T17:12:26.939353Z","iopub.status.idle":"2025-06-19T17:12:28.123438Z","shell.execute_reply.started":"2025-06-19T17:12:26.939333Z","shell.execute_reply":"2025-06-19T17:12:28.122884Z"}},"outputs":[],"execution_count":25},{"id":"mO1x8Ugq0Ihd","cell_type":"markdown","source":"### Generate model ops","metadata":{"id":"mO1x8Ugq0Ihd"}},{"id":"uOQtfKM60Les","cell_type":"code","source":"# Move the model to the correct device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n_ = model.to(device)","metadata":{"id":"uOQtfKM60Les","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T14:02:29.657311Z","iopub.execute_input":"2025-06-19T14:02:29.657551Z","iopub.status.idle":"2025-06-19T14:02:30.187221Z","shell.execute_reply.started":"2025-06-19T14:02:29.657535Z","shell.execute_reply":"2025-06-19T14:02:30.186653Z"}},"outputs":[],"execution_count":10},{"id":"Wgmytw152EaM","cell_type":"code","source":"def generate_prompt_output(prompts, model, device):\n  # Generate few-shot predictions in batches\n  batch_size = 20\n  preds = []\n\n  # Select a larger subset for demonstration\n  subset = zero_shot_prompts\n\n  for i in tqdm(range(0, len(prompts), batch_size)):\n      batch_subset = []\n      for j in range(i, min(i + batch_size, len(prompts))):\n          batch_subset.append(prompts[j])\n\n      batch_prompts = batch_subset\n\n      # Tokenize and move inputs to the correct device\n      inputs = tokenizer(batch_prompts, return_tensors=\"pt\", truncation=True, max_length=2024, padding=True)\n      inputs = {k: v.to(device) for k, v in inputs.items()}  # Fix: move input tensors to the device\n\n      # Generate predictions\n      outputs = model.generate(**inputs, max_length=64)  # Do NOT call .to(device) here\n\n      # Decode predictions\n      batch_preds = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n      preds.extend(batch_preds)\n\n  return preds","metadata":{"id":"Wgmytw152EaM","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T14:02:30.189315Z","iopub.execute_input":"2025-06-19T14:02:30.189585Z","iopub.status.idle":"2025-06-19T14:02:30.195214Z","shell.execute_reply.started":"2025-06-19T14:02:30.189567Z","shell.execute_reply":"2025-06-19T14:02:30.194493Z"}},"outputs":[],"execution_count":11},{"id":"2QEHD2jG2kjV","cell_type":"code","source":"zero_shot_results = generate_prompt_output(zero_shot_prompts, model, device)\n\nfile_name = \"zero_shot_testset.pkl\"\nfile_path = os.path.join(data_path, file_name)\n\ntry:\n    with open(file_path, 'wb') as f:\n        pickle.dump(zero_shot_results, f)\n    print(f\"Successfully saved the list as pickle to: {file_path}\")\nexcept Exception as e:\n    print(f\"An error occurred while saving the pickle file: {e}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2QEHD2jG2kjV","outputId":"ffa67cb0-06dd-432b-99e1-90ee6e4c30e7","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T14:02:30.195965Z","iopub.execute_input":"2025-06-19T14:02:30.196212Z","iopub.status.idle":"2025-06-19T15:05:51.389311Z","shell.execute_reply.started":"2025-06-19T14:02:30.196191Z","shell.execute_reply":"2025-06-19T15:05:51.388495Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 567/567 [1:03:21<00:00,  6.70s/it]","output_type":"stream"},{"name":"stdout","text":"Successfully saved the list as pickle to: /kaggle/working/zero_shot_testset.pkl\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":12},{"id":"JZcZ5wbrNprO","cell_type":"code","source":"one_shot_results = generate_prompt_output(one_shot_prompts, model, device)\n\nfile_name = \"one_shot_testset.pkl\"\nfile_path = os.path.join(data_path, file_name)\n\ntry:\n    with open(file_path, 'wb') as f:\n        pickle.dump(one_shot_results, f)\n    print(f\"Successfully saved the list as pickle to: {file_path}\")\nexcept Exception as e:\n    print(f\"An error occurred while saving the pickle file: {e}\")","metadata":{"id":"JZcZ5wbrNprO","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T15:05:51.390150Z","iopub.execute_input":"2025-06-19T15:05:51.390434Z","iopub.status.idle":"2025-06-19T16:31:34.887619Z","shell.execute_reply.started":"2025-06-19T15:05:51.390408Z","shell.execute_reply":"2025-06-19T16:31:34.886924Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 567/567 [1:25:43<00:00,  9.07s/it]","output_type":"stream"},{"name":"stdout","text":"Successfully saved the list as pickle to: /kaggle/working/one_shot_testset.pkl\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"id":"0QNT6evdNp6O","cell_type":"code","source":"# # few_shot_results = generate_prompt_output(few_shot_prompts, model, device)\n\nfile_path = \"/kaggle/input/few-shot-testset-pkl/few_shot_testset.pkl\"\n\ntry:\n    with open(file_path, 'rb') as f:\n        few_shot_results = pickle.load(f)\n    print(f\"Successfully loaded the list from pickle file: {file_path}\")\n    # Now you can work with the 'few_shot_preds' variable\n    # For example, you can print the first few elements:\n    # print(few_shot_preds[:5])\nexcept FileNotFoundError:\n    print(f\"Error: The file '{file_path}' was not found.\")\nexcept Exception as e:\n    print(f\"An error occurred while loading the pickle file: {e}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0QNT6evdNp6O","outputId":"439ead62-cb4f-49b7-f595-4787df7b802a","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:31:34.888418Z","iopub.execute_input":"2025-06-19T16:31:34.888681Z","iopub.status.idle":"2025-06-19T16:31:34.924761Z","shell.execute_reply.started":"2025-06-19T16:31:34.888655Z","shell.execute_reply":"2025-06-19T16:31:34.924205Z"}},"outputs":[{"name":"stdout","text":"Successfully loaded the list from pickle file: /kaggle/input/few-shot-testset-pkl/few_shot_testset.pkl\n","output_type":"stream"}],"execution_count":14},{"id":"lC6X_PBr__OV","cell_type":"markdown","source":"### Calculate Evaluation metrics","metadata":{"id":"lC6X_PBr__OV"}},{"id":"UHP74IzM_qBN","cell_type":"code","source":"# Ensure you have the necessary evaluation metrics loaded\nrouge = evaluate.load(\"rouge\")\n\n# --- Calculate Metrics ---\n\n# Zero-shot\nzero_shot_rouge = rouge.compute(predictions=zero_shot_results, references=references)\n_, _, zero_shot_bertscore_f1 = score(zero_shot_results, references, lang=\"en\", verbose=True)\n\n# One-shot\none_shot_rouge = rouge.compute(predictions=one_shot_results, references=references)\n_, _, one_shot_bertscore_f1 = score(one_shot_results, references, lang=\"en\", verbose=True)\n\n# Few-shot\nfew_shot_rouge = rouge.compute(predictions=few_shot_results, references=references)\n_, _, few_shot_bertscore_f1 = score(few_shot_results, references, lang=\"en\", verbose=True, device= device)\n\n# --- Prepare Data for DataFrame ---\n\nresults = {\n    ('Zero-shot', model_name): {\n        'ROUGE-1': zero_shot_rouge['rouge1'],\n        'ROUGE-2': zero_shot_rouge['rouge2'],\n        'ROUGE-L': zero_shot_rouge['rougeL'],\n        'BERTScore F1': zero_shot_bertscore_f1.mean().item()\n    },\n    ('One-shot', model_name): {\n        'ROUGE-1': one_shot_rouge['rouge1'],\n        'ROUGE-2': one_shot_rouge['rouge2'],\n        'ROUGE-L': one_shot_rouge['rougeL'],\n        'BERTScore F1': one_shot_bertscore_f1.mean().item()\n    },\n    ('Few-shot', model_name): {\n        'ROUGE-1': few_shot_rouge['rouge1'],\n        'ROUGE-2': few_shot_rouge['rouge2'],\n        'ROUGE-L': few_shot_rouge['rougeL'],\n        'BERTScore F1': few_shot_bertscore_f1.mean().item()\n    }\n}\n\n# --- Create DataFrame ---\n\ndf_results = pd.DataFrame.from_dict(results, orient='index')\n\n# Set the index names\ndf_results.index.names = ['Prompt Type', 'Model']","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":529,"referenced_widgets":["0fc028aa93e34005bf3b4d6b4c2e0e32","4b91d257db854215b3ccbb466c0aa84d","8f7889c6a73643e2ab38e088863fd201","66cf53e8824f49daa82c51b54dc5ee09","1a2194943b8046c8aeefe8b7655458e0","e195bb7c16d944acad485baaf13552e8","31ffa63cc4b54a6b88a06d5b7de85ea9","5454094b3e774609bf89c9dd212d8e3b","ab8592b7855e4a90a797481ffa77a630","5b5e6911821e4ff18898401ed45a1829","19d324a3d4724debb4a9c1cb220c9a34"]},"id":"UHP74IzM_qBN","outputId":"fb7e153d-a75a-4fdb-b1b5-daa179ce3f51","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:59:40.523762Z","iopub.execute_input":"2025-06-19T16:59:40.524332Z","iopub.status.idle":"2025-06-19T17:06:20.658476Z","shell.execute_reply.started":"2025-06-19T16:59:40.524307Z","shell.execute_reply":"2025-06-19T17:06:20.657860Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"calculating scores...\ncomputing bert embedding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/354 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00ffc4f7cf834062b58b6aa16a325afb"}},"metadata":{}},{"name":"stdout","text":"computing greedy matching.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/178 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23c0d255227f4326b775b6bb8b1f245b"}},"metadata":{}},{"name":"stderr","text":"Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","output_type":"stream"},{"name":"stdout","text":"done in 125.71 seconds, 90.16 sentences/sec\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"calculating scores...\ncomputing bert embedding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/354 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"661de0ec35474c65a66c8ade56e881ed"}},"metadata":{}},{"name":"stdout","text":"computing greedy matching.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/178 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c39f043e02f44a1876dac9c2e9d8ba6"}},"metadata":{}},{"name":"stdout","text":"done in 123.51 seconds, 91.77 sentences/sec\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"calculating scores...\ncomputing bert embedding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/354 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29b0fe576b2c4a04b0d43bd3381821c5"}},"metadata":{}},{"name":"stdout","text":"computing greedy matching.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/178 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2921f2d3b584763bcf96d5136ad6dba"}},"metadata":{}},{"name":"stderr","text":"Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","output_type":"stream"},{"name":"stdout","text":"done in 124.03 seconds, 91.38 sentences/sec\n","output_type":"stream"}],"execution_count":16},{"id":"1wYBVPPdQ99o","cell_type":"code","source":"# Display the DataFrame\nprint(df_results)","metadata":{"id":"1wYBVPPdQ99o","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T17:06:20.659627Z","iopub.execute_input":"2025-06-19T17:06:20.659846Z","iopub.status.idle":"2025-06-19T17:06:20.671781Z","shell.execute_reply.started":"2025-06-19T17:06:20.659829Z","shell.execute_reply":"2025-06-19T17:06:20.671185Z"}},"outputs":[{"name":"stdout","text":"                                  ROUGE-1   ROUGE-2   ROUGE-L  BERTScore F1\nPrompt Type Model                                                          \nZero-shot   google/flan-t5-base  0.338143  0.119003  0.266704      0.897449\nOne-shot    google/flan-t5-base  0.338109  0.119825  0.267820      0.897942\nFew-shot    google/flan-t5-base  0.337940  0.119473  0.268085      0.897745\n","output_type":"stream"}],"execution_count":17},{"id":"zV4XDPT2UAwv","cell_type":"code","source":"file_name = \"results.pkl\"\nfile_path = os.path.join(data_path, file_name)\n\ntry:\n    df_results.to_pickle(file_path)\n    print(f\"Successfully saved the DataFrame as pickle to: {file_path}\")\nexcept Exception as e:\n    print(f\"An error occurred while saving the pickle file: {e}\")","metadata":{"id":"zV4XDPT2UAwv","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T17:06:20.672536Z","iopub.execute_input":"2025-06-19T17:06:20.672752Z","iopub.status.idle":"2025-06-19T17:06:20.678120Z","shell.execute_reply.started":"2025-06-19T17:06:20.672729Z","shell.execute_reply":"2025-06-19T17:06:20.677569Z"}},"outputs":[{"name":"stdout","text":"Successfully saved the DataFrame as pickle to: /kaggle/working/results.pkl\n","output_type":"stream"}],"execution_count":18},{"id":"418c6c56-5e98-4074-a5f1-5c78725ba681","cell_type":"code","source":"\nprint(zero_shot_results[1578],'\\n',\none_shot_results[1578], '\\n',\nfew_shot_results[1578])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T17:10:07.859597Z","iopub.execute_input":"2025-06-19T17:10:07.859878Z","iopub.status.idle":"2025-06-19T17:10:07.864732Z","shell.execute_reply.started":"2025-06-19T17:10:07.859859Z","shell.execute_reply":"2025-06-19T17:10:07.863882Z"}},"outputs":[{"name":"stdout","text":"A lifeboat crew in St Abbs have reopened their pagers after a row over the closure of the station. \n A lifeboat station in the Borders has been reopened after a row over the closure of its lifeboat. \n A lifeboat station in St Abbs has been reopened after a row over the closure of the station.\n","output_type":"stream"}],"execution_count":23},{"id":"fb6a1fc4-c070-4d4d-8bcb-43d1257dffe8","cell_type":"code","source":"print(zero_shot_prompts[1578],'\\n', 50*'===', '\\n',\none_shot_prompts[1578], '\\n', 50*'===', '\\n',\nfew_shot_prompts[1578])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T17:13:36.284636Z","iopub.execute_input":"2025-06-19T17:13:36.285302Z","iopub.status.idle":"2025-06-19T17:13:36.289540Z","shell.execute_reply.started":"2025-06-19T17:13:36.285279Z","shell.execute_reply":"2025-06-19T17:13:36.288690Z"}},"outputs":[{"name":"stdout","text":"Summarize the input text.\n\n ### INPUT TEXT\nDocument:The volunteers were angry at the RNLI's decision to shut down the station later this year.\nThey had said they would no longer use the lifeboat to respond to emergencies, and would instead use their own boats.\nBut the crew agreed to take back their pagers at a meeting on Friday night.\nIn a statement, the crew members said they felt they had to do so ahead of the busy summer diving season, but they pledged to continue campaigning to save the St Abbs station.\nThere has been a lifeboat station in St Abbs for more than 100 years. The local volunteers have been credited with saving hundred of lives in and around the seaside town on the east coast of the Borders.\nBut following a review the RNLI announced last week that the St Abbs boat was no longer needed and in future cover would be provided with an additional boat in nearby Eyemouth.\nSupporters of the station have argued that closing it would put lives at risk.\nSummary:[Fill the summary] \n ====================================================================================================================================================== \n Task: Summarize the input text. An example is provided below. \n### EXAMPLE:\nDocument: The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\nRepair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\nTrains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\nMany businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\nFirst Minister Nicola Sturgeon visited the area to inspect the damage.\nThe waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\nJeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\nHowever, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\n\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we're neglected or forgotten,\" she said.\n\"That may not be true but it is perhaps my perspective over the last few days.\n\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\nMeanwhile, a flood alert remains in place across the Borders because of the constant rain.\nPeebles was badly hit by problems, sparking calls to introduce more defences in the area.\nScottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\nThe Labour Party's deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\nHe said it was important to get the flood protection plan right but backed calls to speed up the process.\n\"I was quite taken aback by the amount of damage that has been done,\" he said.\n\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\nHe said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\nHave you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.\nSummary: Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.\n\n### INPUT TEXT:\nDocument: The volunteers were angry at the RNLI's decision to shut down the station later this year.\nThey had said they would no longer use the lifeboat to respond to emergencies, and would instead use their own boats.\nBut the crew agreed to take back their pagers at a meeting on Friday night.\nIn a statement, the crew members said they felt they had to do so ahead of the busy summer diving season, but they pledged to continue campaigning to save the St Abbs station.\nThere has been a lifeboat station in St Abbs for more than 100 years. The local volunteers have been credited with saving hundred of lives in and around the seaside town on the east coast of the Borders.\nBut following a review the RNLI announced last week that the St Abbs boat was no longer needed and in future cover would be provided with an additional boat in nearby Eyemouth.\nSupporters of the station have argued that closing it would put lives at risk.\nSummary:[Fill the summary] \n ====================================================================================================================================================== \n Task: Summarize the input text. Examples are provided below. \n### EXAMPLE:\nDocument: The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\nRepair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\nTrains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\nMany businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\nFirst Minister Nicola Sturgeon visited the area to inspect the damage.\nThe waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\nJeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\nHowever, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\n\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we're neglected or forgotten,\" she said.\n\"That may not be true but it is perhaps my perspective over the last few days.\n\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\nMeanwhile, a flood alert remains in place across the Borders because of the constant rain.\nPeebles was badly hit by problems, sparking calls to introduce more defences in the area.\nScottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\nThe Labour Party's deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\nHe said it was important to get the flood protection plan right but backed calls to speed up the process.\n\"I was quite taken aback by the amount of damage that has been done,\" he said.\n\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\nHe said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\nHave you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.\nSummary: Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.\n\n### EXAMPLE:\nDocument: A fire alarm went off at the Holiday Inn in Hope Street at about 04:20 BST on Saturday and guests were asked to leave the hotel.\nAs they gathered outside they saw the two buses, parked side-by-side in the car park, engulfed by flames.\nOne of the tour groups is from Germany, the other from China and Taiwan. It was their first night in Northern Ireland.\nThe driver of one of the buses said many of the passengers had left personal belongings on board and these had been destroyed.\nBoth groups have organised replacement coaches and will begin their tour of the north coast later than they had planned.\nPolice have appealed for information about the attack.\nInsp David Gibson said: \"It appears as though the fire started under one of the buses before spreading to the second.\n\"While the exact cause is still under investigation, it is thought that the fire was started deliberately.\"\nSummary: Two tourist buses have been destroyed by fire in a suspected arson attack in Belfast city centre.\n\n### INPUT TEXT:\nDocument: The volunteers were angry at the RNLI's decision to shut down the station later this year.\nThey had said they would no longer use the lifeboat to respond to emergencies, and would instead use their own boats.\nBut the crew agreed to take back their pagers at a meeting on Friday night.\nIn a statement, the crew members said they felt they had to do so ahead of the busy summer diving season, but they pledged to continue campaigning to save the St Abbs station.\nThere has been a lifeboat station in St Abbs for more than 100 years. The local volunteers have been credited with saving hundred of lives in and around the seaside town on the east coast of the Borders.\nBut following a review the RNLI announced last week that the St Abbs boat was no longer needed and in future cover would be provided with an additional boat in nearby Eyemouth.\nSupporters of the station have argued that closing it would put lives at risk.\nSummary:[Fill the summary]\n","output_type":"stream"}],"execution_count":29}]}