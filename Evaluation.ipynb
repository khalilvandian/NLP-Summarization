{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1795f27e64fd4fd29e43b37120ebbfb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5da62e903834d7c8ed7a19c209d7de5",
              "IPY_MODEL_9436cd6b5abf40c2bcb8be31a8b7aacb",
              "IPY_MODEL_eba4b427f7334d3fa59a5bfb1ec53e49"
            ],
            "layout": "IPY_MODEL_ee796d4e1f2d4b518e409fd6bc3d660e"
          }
        },
        "a5da62e903834d7c8ed7a19c209d7de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_545faf9398de45e8b35659cb3df77a90",
            "placeholder": "​",
            "style": "IPY_MODEL_a0868445631f44cea547b96ea64bf661",
            "value": "  0%"
          }
        },
        "9436cd6b5abf40c2bcb8be31a8b7aacb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_543075f867104ad8943ab06fb856d619",
            "max": 354,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe269ea7ef1e49778b3782f531e6435e",
            "value": 0
          }
        },
        "eba4b427f7334d3fa59a5bfb1ec53e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7edc5b6fef6b47759cd119dfa69c86e3",
            "placeholder": "​",
            "style": "IPY_MODEL_e86a4213a1d6407c95e27a0c94031467",
            "value": " 0/354 [00:00&lt;?, ?it/s]"
          }
        },
        "ee796d4e1f2d4b518e409fd6bc3d660e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "545faf9398de45e8b35659cb3df77a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0868445631f44cea547b96ea64bf661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "543075f867104ad8943ab06fb856d619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe269ea7ef1e49778b3782f531e6435e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7edc5b6fef6b47759cd119dfa69c86e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e86a4213a1d6407c95e27a0c94031467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "9733de2c",
      "cell_type": "markdown",
      "source": [
        "# Prompting flan-T5-base"
      ],
      "metadata": {
        "id": "9733de2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Config\n",
        "random_seed = 100\n",
        "data_path = \"/kaggle/working/\""
      ],
      "metadata": {
        "id": "K0q-D7U1vL7d"
      },
      "id": "K0q-D7U1vL7d",
      "execution_count": 1,
      "outputs": []
    },
    {
      "id": "d17589d5",
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U datasets\n",
        "!pip install transformers datasets evaluate rouge_score --quiet\n",
        "!pip uninstall keras -y\n",
        "!pip install keras==2.11\n",
        "!pip install bert_score"
      ],
      "metadata": {
        "id": "d17589d5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T08:05:47.321316Z",
          "iopub.execute_input": "2025-06-19T08:05:47.321487Z",
          "iopub.status.idle": "2025-06-19T08:05:59.509270Z",
          "shell.execute_reply.started": "2025-06-19T08:05:47.321471Z",
          "shell.execute_reply": "2025-06-19T08:05:59.508398Z"
        }
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "dZnDJJJSJ-BC",
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch"
      ],
      "metadata": {
        "id": "dZnDJJJSJ-BC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T08:05:59.511264Z",
          "iopub.execute_input": "2025-06-19T08:05:59.511578Z",
          "iopub.status.idle": "2025-06-19T08:06:08.133688Z",
          "shell.execute_reply.started": "2025-06-19T08:05:59.511551Z",
          "shell.execute_reply": "2025-06-19T08:06:08.133158Z"
        }
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os"
      ],
      "metadata": {
        "id": "7lLzzaRcObFo"
      },
      "id": "7lLzzaRcObFo",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data and Model"
      ],
      "metadata": {
        "id": "DSBfAOyAueZ8"
      },
      "id": "DSBfAOyAueZ8"
    },
    {
      "id": "ca2bae17",
      "cell_type": "code",
      "source": [
        "# Full dataset (split included)\n",
        "dataset = load_dataset(\"EdinburghNLP/xsum\")"
      ],
      "metadata": {
        "id": "ca2bae17",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T08:06:08.134435Z",
          "iopub.execute_input": "2025-06-19T08:06:08.134943Z",
          "iopub.status.idle": "2025-06-19T08:06:09.136957Z",
          "shell.execute_reply.started": "2025-06-19T08:06:08.134913Z",
          "shell.execute_reply": "2025-06-19T08:06:09.136396Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6f3b9f-5c7f-4e97-b3db-2ff830a86ea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "# Few-shot examples from training set\n",
        "train_examples = dataset[\"train\"].select(range(2))\n",
        "\n",
        "# Sample a subset of the test set for evaluation\n",
        "test_sample = dataset[\"test\"].shuffle(seed=random_seed)\n",
        "references = [example[\"summary\"] for example in test_sample]"
      ],
      "metadata": {
        "id": "PqFJfBEPwVK8"
      },
      "id": "PqFJfBEPwVK8",
      "execution_count": 15,
      "outputs": []
    },
    {
      "id": "713cbb86",
      "cell_type": "code",
      "source": [
        "model_name = \"google/flan-t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=2024)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "713cbb86",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T08:06:09.137687Z",
          "iopub.execute_input": "2025-06-19T08:06:09.137888Z",
          "iopub.status.idle": "2025-06-19T08:06:09.628661Z",
          "shell.execute_reply.started": "2025-06-19T08:06:09.137871Z",
          "shell.execute_reply": "2025-06-19T08:06:09.628104Z"
        }
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-Shot, One-Shot and Few-Shot Prompts"
      ],
      "metadata": {
        "id": "P0Q9IVuufRQw"
      },
      "id": "P0Q9IVuufRQw"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_zero_shot_prompt(doc):\n",
        "    \"\"\"Builds a zero-shot prompt.\"\"\"\n",
        "    prompt_template = \"Summarize the input text.\\n\\n ### INPUT TEXT\\nDocument:{}\\nSummary:[Fill the summary]\"\n",
        "    return prompt_template.format(doc)\n",
        "\n",
        "def build_one_shot_prompt(doc, train_example):\n",
        "    \"\"\"Builds a one-shot prompt with one example.\"\"\"\n",
        "    prompt = \"\"\n",
        "    prompt += \"Task: Summarize the input text. An example is provided below. \\n\"\n",
        "    prompt += f\"### EXAMPLE:\\nDocument: {train_example['document'].strip()}\\nSummary: {train_example['summary'].strip()}\\n\\n\"\n",
        "    prompt += f\"### INPUT TEXT:\\nDocument: {doc.strip()}\\nSummary:[Fill the summary]\"\n",
        "    return prompt\n",
        "\n",
        "def build_few_shot_prompt(doc, few_shots):\n",
        "    \"\"\"Builds a few-shot prompt with multiple examples.\"\"\"\n",
        "    prompt = \"\"\n",
        "    prompt += \"Task: Summarize the input text. Examples are provided below. \\n\"\n",
        "    for ex in few_shots:\n",
        "        prompt += f\"### EXAMPLE:\\nDocument: {ex['document'].strip()}\\nSummary: {ex['summary'].strip()}\\n\\n\"\n",
        "    prompt += f\"### INPUT TEXT:\\nDocument: {doc.strip()}\\nSummary:[Fill the summary]\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "_CmaGiOifi6Y"
      },
      "execution_count": 8,
      "outputs": [],
      "id": "_CmaGiOifi6Y"
    },
    {
      "cell_type": "code",
      "source": [
        "# document = test_sample[0][\"document\"]\n",
        "\n",
        "# zero_shot_prompts = [build_zero_shot_prompt(document[\"document\"]) for document in test_sample]\n",
        "# one_shot_prompts = [build_one_shot_prompt(document[\"document\"], train_examples[0]) for document in test_sample]\n",
        "# few_shot_prompts = [build_few_shot_prompt(document[\"document\"], train_examples) for document in test_sample]"
      ],
      "metadata": {
        "id": "kdyt0Ho0gY_l"
      },
      "execution_count": 9,
      "outputs": [],
      "id": "kdyt0Ho0gY_l"
    },
    {
      "source": [
        "zero_shot_prompts = []\n",
        "for document in test_sample:\n",
        "    prompt = build_zero_shot_prompt(document[\"document\"])\n",
        "    zero_shot_prompts.append(prompt)\n",
        "\n",
        "one_shot_prompts = []\n",
        "for document in test_sample:\n",
        "    prompt = build_one_shot_prompt(document[\"document\"], train_examples[0])\n",
        "    one_shot_prompts.append(prompt)\n",
        "\n",
        "# few_shot_prompts = []\n",
        "# for document in test_sample:\n",
        "#     prompt = build_few_shot_prompt(document[\"document\"], train_examples)\n",
        "#     few_shot_prompts.append(prompt)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "6yyqabZMQJuw"
      },
      "id": "6yyqabZMQJuw",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate model ops"
      ],
      "metadata": {
        "id": "mO1x8Ugq0Ihd"
      },
      "id": "mO1x8Ugq0Ihd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to the correct device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "_ = model.to(device)"
      ],
      "metadata": {
        "id": "uOQtfKM60Les"
      },
      "id": "uOQtfKM60Les",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_output(prompts, model, device):\n",
        "  # Generate few-shot predictions in batches\n",
        "  batch_size = 5\n",
        "  preds = []\n",
        "\n",
        "  # Select a larger subset for demonstration\n",
        "  subset = zero_shot_prompts\n",
        "\n",
        "  for i in tqdm(range(0, len(prompts), batch_size)):\n",
        "      batch_subset = []\n",
        "      for j in range(i, min(i + batch_size, len(prompts))):\n",
        "          batch_subset.append(prompts[j])\n",
        "\n",
        "      batch_prompts = batch_subset\n",
        "\n",
        "      # Tokenize and move inputs to the correct device\n",
        "      inputs = tokenizer(batch_prompts, return_tensors=\"pt\", truncation=True, max_length=2024, padding=True)\n",
        "      inputs = {k: v.to(device) for k, v in inputs.items()}  # Fix: move input tensors to the device\n",
        "\n",
        "      # Generate predictions\n",
        "      outputs = model.generate(**inputs, max_length=64)  # Do NOT call .to(device) here\n",
        "\n",
        "      # Decode predictions\n",
        "      batch_preds = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "      preds.extend(batch_preds)\n",
        "\n",
        "  return preds"
      ],
      "metadata": {
        "id": "Wgmytw152EaM"
      },
      "id": "Wgmytw152EaM",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_results = generate_prompt_output(zero_shot_prompts, model, device)\n",
        "\n",
        "file_name = \"zero_shot_testset_test00.pkl\"\n",
        "file_path = os.path.join(data_path, file_name)\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(one_shot_results, f)\n",
        "    print(f\"Successfully saved the list as pickle to: {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the pickle file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QEHD2jG2kjV",
        "outputId": "ffa67cb0-06dd-432b-99e1-90ee6e4c30e7"
      },
      "id": "2QEHD2jG2kjV",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [02:05<00:00, 62.74s/it]\n",
            "100%|██████████| 2/2 [03:06<00:00, 93.07s/it]\n",
            "100%|██████████| 2/2 [03:15<00:00, 97.75s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_shot_results = generate_prompt_output(one_shot_prompts, model, device)\n",
        "\n",
        "file_name = \"one_shot_testset_test00.pkl\"\n",
        "file_path = os.path.join(data_path, file_name)\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(one_shot_results, f)\n",
        "    print(f\"Successfully saved the list as pickle to: {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the pickle file: {e}\")"
      ],
      "metadata": {
        "id": "JZcZ5wbrNprO"
      },
      "id": "JZcZ5wbrNprO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# few_shot_results = generate_prompt_output(few_shot_prompts, model, device)\n",
        "\n",
        "file_path = '/content/few_shot_testset.pkl'\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'rb') as f:\n",
        "        few_shot_results = pickle.load(f)\n",
        "    print(f\"Successfully loaded the list from pickle file: {file_path}\")\n",
        "    # Now you can work with the 'few_shot_preds' variable\n",
        "    # For example, you can print the first few elements:\n",
        "    # print(few_shot_preds[:5])\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the pickle file: {e}\")"
      ],
      "metadata": {
        "id": "0QNT6evdNp6O",
        "outputId": "439ead62-cb4f-49b7-f595-4787df7b802a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0QNT6evdNp6O",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded the list from pickle file: /content/few_shot_testset.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Evaluation metrics"
      ],
      "metadata": {
        "id": "lC6X_PBr__OV"
      },
      "id": "lC6X_PBr__OV"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import evaluate\n",
        "from bert_score import score\n",
        "import torch\n",
        "\n",
        "# Ensure you have the necessary evaluation metrics loaded\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "# --- Calculate Metrics ---\n",
        "\n",
        "# # Zero-shot\n",
        "# zero_shot_rouge = rouge.compute(predictions=zero_shot_results, references=references)\n",
        "# _, _, zero_shot_bertscore_f1 = score(zero_shot_results, references, lang=\"en\", verbose=True)\n",
        "\n",
        "# # One-shot\n",
        "# one_shot_rouge = rouge.compute(predictions=one_shot_results, references=references)\n",
        "# _, _, one_shot_bertscore_f1 = score(one_shot_results, references, lang=\"en\", verbose=True)\n",
        "\n",
        "# Few-shot\n",
        "few_shot_rouge = rouge.compute(predictions=few_shot_results, references=references)\n",
        "_, _, few_shot_bertscore_f1 = score(few_shot_results, references, lang=\"en\", verbose=True)\n",
        "\n",
        "\n",
        "# --- Prepare Data for DataFrame ---\n",
        "\n",
        "results = {\n",
        "    # ('Zero-shot', model_name): {\n",
        "    #     'ROUGE-1': zero_shot_rouge['rouge1'],\n",
        "    #     'ROUGE-2': zero_shot_rouge['rouge2'],\n",
        "    #     'ROUGE-L': zero_shot_rouge['rougeL'],\n",
        "    #     'BERTScore F1': zero_shot_bertscore_f1.mean().item()\n",
        "    # },\n",
        "    # ('One-shot', model_name): {\n",
        "    #     'ROUGE-1': one_shot_rouge['rouge1'],\n",
        "    #     'ROUGE-2': one_shot_rouge['rouge2'],\n",
        "    #     'ROUGE-L': one_shot_rouge['rougeL'],\n",
        "    #     'BERTScore F1': one_shot_bertscore_f1.mean().item()\n",
        "    # },\n",
        "    ('Few-shot', model_name): {\n",
        "        'ROUGE-1': few_shot_rouge['rouge1'],\n",
        "        'ROUGE-2': few_shot_rouge['rouge2'],\n",
        "        'ROUGE-L': few_shot_rouge['rougeL'],\n",
        "        'BERTScore F1': few_shot_bertscore_f1.mean().item()\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- Create DataFrame ---\n",
        "\n",
        "df_results = pd.DataFrame.from_dict(results, orient='index')\n",
        "\n",
        "# Set the index names\n",
        "df_results.index.names = ['Prompt Type', 'Model']"
      ],
      "metadata": {
        "id": "UHP74IzM_qBN",
        "outputId": "5fb981f2-227b-4c95-9779-0ede3b8bf89d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "1795f27e64fd4fd29e43b37120ebbfb5",
            "a5da62e903834d7c8ed7a19c209d7de5",
            "9436cd6b5abf40c2bcb8be31a8b7aacb",
            "eba4b427f7334d3fa59a5bfb1ec53e49",
            "ee796d4e1f2d4b518e409fd6bc3d660e",
            "545faf9398de45e8b35659cb3df77a90",
            "a0868445631f44cea547b96ea64bf661",
            "543075f867104ad8943ab06fb856d619",
            "fe269ea7ef1e49778b3782f531e6435e",
            "7edc5b6fef6b47759cd119dfa69c86e3",
            "e86a4213a1d6407c95e27a0c94031467"
          ]
        }
      },
      "id": "UHP74IzM_qBN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/354 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1795f27e64fd4fd29e43b37120ebbfb5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the DataFrame\n",
        "print(df_results)"
      ],
      "metadata": {
        "id": "1wYBVPPdQ99o"
      },
      "id": "1wYBVPPdQ99o",
      "execution_count": null,
      "outputs": []
    }
  ]
}