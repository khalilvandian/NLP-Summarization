{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU",
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "9733de2c",
      "cell_type": "markdown",
      "source": [
        "# Prompting flan-T5-base"
      ],
      "metadata": {
        "id": "9733de2c"
      }
    },
    {
      "id": "K0q-D7U1vL7d",
      "cell_type": "code",
      "source": [
        "## Config\n",
        "random_seed = 100\n",
        "data_path = \"/kaggle/working/\""
      ],
      "metadata": {
        "id": "K0q-D7U1vL7d",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T13:50:20.892187Z",
          "iopub.execute_input": "2025-06-19T13:50:20.892373Z",
          "iopub.status.idle": "2025-06-19T13:50:20.899317Z",
          "shell.execute_reply.started": "2025-06-19T13:50:20.892357Z",
          "shell.execute_reply": "2025-06-19T13:50:20.898696Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d17589d5",
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U datasets\n",
        "!pip install transformers datasets evaluate rouge_score --quiet\n",
        "!pip uninstall keras -y\n",
        "!pip install keras==2.11\n",
        "!pip install bert_score"
      ],
      "metadata": {
        "id": "d17589d5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T13:50:20.900009Z",
          "iopub.execute_input": "2025-06-19T13:50:20.900172Z",
          "iopub.status.idle": "2025-06-19T13:50:36.026848Z",
          "shell.execute_reply.started": "2025-06-19T13:50:20.900159Z",
          "shell.execute_reply": "2025-06-19T13:50:36.025873Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "dZnDJJJSJ-BC",
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "import pandas as pd\n",
        "from bert_score import score\n",
        "import pickle\n",
        "import os"
      ],
      "metadata": {
        "id": "dZnDJJJSJ-BC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T13:50:36.028113Z",
          "iopub.execute_input": "2025-06-19T13:50:36.028363Z",
          "iopub.status.idle": "2025-06-19T13:50:44.609991Z",
          "shell.execute_reply.started": "2025-06-19T13:50:36.028336Z",
          "shell.execute_reply": "2025-06-19T13:50:44.609233Z"
        },
        "outputId": "ebc5a55e-e25e-4c18-c53c-2f9ac40160c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-06-19 13:50:40.237407: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750341040.262774     253 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750341040.270596     253 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "DSBfAOyAueZ8",
      "cell_type": "markdown",
      "source": [
        "## Load Data and Model"
      ],
      "metadata": {
        "id": "DSBfAOyAueZ8"
      }
    },
    {
      "id": "ca2bae17",
      "cell_type": "code",
      "source": [
        "# Full dataset (split included)\n",
        "dataset = load_dataset(\"EdinburghNLP/xsum\")"
      ],
      "metadata": {
        "id": "ca2bae17",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T13:50:44.610905Z",
          "iopub.execute_input": "2025-06-19T13:50:44.611364Z",
          "iopub.status.idle": "2025-06-19T13:50:45.871353Z",
          "shell.execute_reply.started": "2025-06-19T13:50:44.611345Z",
          "shell.execute_reply": "2025-06-19T13:50:45.870822Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "PqFJfBEPwVK8",
      "cell_type": "code",
      "source": [
        "# Few-shot examples from training set\n",
        "train_examples = dataset[\"train\"].select(range(2))\n",
        "\n",
        "# Sample a subset of the test set for evaluation\n",
        "test_sample = dataset[\"test\"]\n",
        "references = [example[\"summary\"] for example in test_sample]"
      ],
      "metadata": {
        "id": "PqFJfBEPwVK8",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T13:50:45.872089Z",
          "iopub.execute_input": "2025-06-19T13:50:45.872360Z",
          "iopub.status.idle": "2025-06-19T13:50:46.191954Z",
          "shell.execute_reply.started": "2025-06-19T13:50:45.872334Z",
          "shell.execute_reply": "2025-06-19T13:50:46.191306Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "713cbb86",
      "cell_type": "code",
      "source": [
        "model_name = \"google/flan-t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=2024)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "713cbb86",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T13:50:46.194371Z",
          "iopub.execute_input": "2025-06-19T13:50:46.194638Z",
          "iopub.status.idle": "2025-06-19T13:50:46.754364Z",
          "shell.execute_reply.started": "2025-06-19T13:50:46.194620Z",
          "shell.execute_reply": "2025-06-19T13:50:46.753634Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "P0Q9IVuufRQw",
      "cell_type": "markdown",
      "source": [
        "## Zero-Shot, One-Shot and Few-Shot Prompts"
      ],
      "metadata": {
        "id": "P0Q9IVuufRQw"
      }
    },
    {
      "id": "_CmaGiOifi6Y",
      "cell_type": "code",
      "source": [
        "def build_zero_shot_prompt(doc):\n",
        "    \"\"\"Builds a zero-shot prompt.\"\"\"\n",
        "    prompt_template = \"Summarize the input text.\\n\\n ### INPUT TEXT\\nDocument:{}\\nSummary:[Fill the summary]\"\n",
        "    return prompt_template.format(doc)\n",
        "\n",
        "def build_one_shot_prompt(doc, train_example):\n",
        "    \"\"\"Builds a one-shot prompt with one example.\"\"\"\n",
        "    prompt = \"\"\n",
        "    prompt += \"Task: Summarize the input text. An example is provided below. \\n\"\n",
        "    prompt += f\"### EXAMPLE:\\nDocument: {train_example['document'].strip()}\\nSummary: {train_example['summary'].strip()}\\n\\n\"\n",
        "    prompt += f\"### INPUT TEXT:\\nDocument: {doc.strip()}\\nSummary:[Fill the summary]\"\n",
        "    return prompt\n",
        "\n",
        "def build_few_shot_prompt(doc, few_shots):\n",
        "    \"\"\"Builds a few-shot prompt with multiple examples.\"\"\"\n",
        "    prompt = \"\"\n",
        "    prompt += \"Task: Summarize the input text. Examples are provided below. \\n\"\n",
        "    for ex in few_shots:\n",
        "        prompt += f\"### EXAMPLE:\\nDocument: {ex['document'].strip()}\\nSummary: {ex['summary'].strip()}\\n\\n\"\n",
        "    prompt += f\"### INPUT TEXT:\\nDocument: {doc.strip()}\\nSummary:[Fill the summary]\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "_CmaGiOifi6Y",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T13:50:46.755099Z",
          "iopub.execute_input": "2025-06-19T13:50:46.755388Z",
          "iopub.status.idle": "2025-06-19T13:50:46.760784Z",
          "shell.execute_reply.started": "2025-06-19T13:50:46.755364Z",
          "shell.execute_reply": "2025-06-19T13:50:46.759898Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "kdyt0Ho0gY_l",
      "cell_type": "code",
      "source": [
        "# document = test_sample[0][\"document\"]\n",
        "\n",
        "# zero_shot_prompts = [build_zero_shot_prompt(document[\"document\"]) for document in test_sample]\n",
        "# one_shot_prompts = [build_one_shot_prompt(document[\"document\"], train_examples[0]) for document in test_sample]\n",
        "# few_shot_prompts = [build_few_shot_prompt(document[\"document\"], train_examples) for document in test_sample]"
      ],
      "metadata": {
        "id": "kdyt0Ho0gY_l",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T13:50:46.761452Z",
          "iopub.execute_input": "2025-06-19T13:50:46.761753Z",
          "iopub.status.idle": "2025-06-19T13:50:46.779201Z",
          "shell.execute_reply.started": "2025-06-19T13:50:46.761728Z",
          "shell.execute_reply": "2025-06-19T13:50:46.778447Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6yyqabZMQJuw",
      "cell_type": "code",
      "source": [
        "zero_shot_prompts = []\n",
        "for document in test_sample:\n",
        "    prompt = build_zero_shot_prompt(document[\"document\"])\n",
        "    zero_shot_prompts.append(prompt)\n",
        "\n",
        "one_shot_prompts = []\n",
        "for document in test_sample:\n",
        "    prompt = build_one_shot_prompt(document[\"document\"], train_examples[0])\n",
        "    one_shot_prompts.append(prompt)\n",
        "\n",
        "# few_shot_prompts = []\n",
        "# for document in test_sample:\n",
        "#     prompt = build_few_shot_prompt(document[\"document\"], train_examples)\n",
        "#     few_shot_prompts.append(prompt)"
      ],
      "metadata": {
        "id": "6yyqabZMQJuw",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T13:50:46.780018Z",
          "iopub.execute_input": "2025-06-19T13:50:46.780521Z",
          "iopub.status.idle": "2025-06-19T13:50:48.148641Z",
          "shell.execute_reply.started": "2025-06-19T13:50:46.780497Z",
          "shell.execute_reply": "2025-06-19T13:50:48.148007Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "mO1x8Ugq0Ihd",
      "cell_type": "markdown",
      "source": [
        "### Generate model ops"
      ],
      "metadata": {
        "id": "mO1x8Ugq0Ihd"
      }
    },
    {
      "id": "uOQtfKM60Les",
      "cell_type": "code",
      "source": [
        "# Move the model to the correct device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "_ = model.to(device)"
      ],
      "metadata": {
        "id": "uOQtfKM60Les",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T13:50:48.149351Z",
          "iopub.execute_input": "2025-06-19T13:50:48.149571Z",
          "iopub.status.idle": "2025-06-19T13:50:48.635918Z",
          "shell.execute_reply.started": "2025-06-19T13:50:48.149553Z",
          "shell.execute_reply": "2025-06-19T13:50:48.635109Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "Wgmytw152EaM",
      "cell_type": "code",
      "source": [
        "def generate_prompt_output(prompts, model, device):\n",
        "  # Generate few-shot predictions in batches\n",
        "  batch_size = 20\n",
        "  preds = []\n",
        "\n",
        "  # Select a larger subset for demonstration\n",
        "  subset = zero_shot_prompts\n",
        "\n",
        "  for i in tqdm(range(0, len(prompts), batch_size)):\n",
        "      batch_subset = []\n",
        "      for j in range(i, min(i + batch_size, len(prompts))):\n",
        "          batch_subset.append(prompts[j])\n",
        "\n",
        "      batch_prompts = batch_subset\n",
        "\n",
        "      # Tokenize and move inputs to the correct device\n",
        "      inputs = tokenizer(batch_prompts, return_tensors=\"pt\", truncation=True, max_length=2024, padding=True)\n",
        "      inputs = {k: v.to(device) for k, v in inputs.items()}  # Fix: move input tensors to the device\n",
        "\n",
        "      # Generate predictions\n",
        "      outputs = model.generate(**inputs, max_length=64)  # Do NOT call .to(device) here\n",
        "\n",
        "      # Decode predictions\n",
        "      batch_preds = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "      preds.extend(batch_preds)\n",
        "\n",
        "  return preds"
      ],
      "metadata": {
        "id": "Wgmytw152EaM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T13:50:48.636813Z",
          "iopub.execute_input": "2025-06-19T13:50:48.637046Z",
          "iopub.status.idle": "2025-06-19T13:50:48.642604Z",
          "shell.execute_reply.started": "2025-06-19T13:50:48.637029Z",
          "shell.execute_reply": "2025-06-19T13:50:48.641829Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2QEHD2jG2kjV",
      "cell_type": "code",
      "source": [
        "zero_shot_results = generate_prompt_output(zero_shot_prompts, model, device)\n",
        "\n",
        "file_name = \"zero_shot_testset.pkl\"\n",
        "file_path = os.path.join(data_path, file_name)\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(zero_shot_results, f)\n",
        "    print(f\"Successfully saved the list as pickle to: {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the pickle file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QEHD2jG2kjV",
        "outputId": "ffa67cb0-06dd-432b-99e1-90ee6e4c30e7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-19T13:50:48.643451Z",
          "iopub.execute_input": "2025-06-19T13:50:48.643688Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "  1%|          | 3/567 [00:21<1:08:22,  7.27s/it]",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "JZcZ5wbrNprO",
      "cell_type": "code",
      "source": [
        "one_shot_results = generate_prompt_output(one_shot_prompts, model, device)\n",
        "\n",
        "file_name = \"one_shot_testset.pkl\"\n",
        "file_path = os.path.join(data_path, file_name)\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(one_shot_results, f)\n",
        "    print(f\"Successfully saved the list as pickle to: {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the pickle file: {e}\")"
      ],
      "metadata": {
        "id": "JZcZ5wbrNprO",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0QNT6evdNp6O",
      "cell_type": "code",
      "source": [
        "# # few_shot_results = generate_prompt_output(few_shot_prompts, model, device)\n",
        "\n",
        "file_path = \"/kaggle/input/few-shot-testset-pkl/few_shot_testset.pkl\"\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'rb') as f:\n",
        "        few_shot_results = pickle.load(f)\n",
        "    print(f\"Successfully loaded the list from pickle file: {file_path}\")\n",
        "    # Now you can work with the 'few_shot_preds' variable\n",
        "    # For example, you can print the first few elements:\n",
        "    # print(few_shot_preds[:5])\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the pickle file: {e}\")"
      ],
      "metadata": {
        "id": "0QNT6evdNp6O",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "lC6X_PBr__OV",
      "cell_type": "markdown",
      "source": [
        "### Calculate Evaluation metrics"
      ],
      "metadata": {
        "id": "lC6X_PBr__OV"
      }
    },
    {
      "id": "UHP74IzM_qBN",
      "cell_type": "code",
      "source": [
        "# Ensure you have the necessary evaluation metrics loaded\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "# --- Calculate Metrics ---\n",
        "\n",
        "# Zero-shot\n",
        "zero_shot_rouge = rouge.compute(predictions=zero_shot_results, references=references)\n",
        "_, _, zero_shot_bertscore_f1 = score(zero_shot_results, references, lang=\"en\", verbose=True)\n",
        "\n",
        "# One-shot\n",
        "one_shot_rouge = rouge.compute(predictions=one_shot_results, references=references)\n",
        "_, _, one_shot_bertscore_f1 = score(one_shot_results, references, lang=\"en\", verbose=True)\n",
        "\n",
        "# Few-shot\n",
        "# few_shot_rouge = rouge.compute(predictions=few_shot_results, references=references)\n",
        "# _, _, few_shot_bertscore_f1 = score(few_shot_results, references, lang=\"en\", verbose=True, device= device)\n",
        "\n",
        "# --- Prepare Data for DataFrame ---\n",
        "\n",
        "results = {\n",
        "    ('Zero-shot', model_name): {\n",
        "        'ROUGE-1': zero_shot_rouge['rouge1'],\n",
        "        'ROUGE-2': zero_shot_rouge['rouge2'],\n",
        "        'ROUGE-L': zero_shot_rouge['rougeL'],\n",
        "        'BERTScore F1': zero_shot_bertscore_f1.mean().item()\n",
        "    },\n",
        "    ('One-shot', model_name): {\n",
        "        'ROUGE-1': one_shot_rouge['rouge1'],\n",
        "        'ROUGE-2': one_shot_rouge['rouge2'],\n",
        "        'ROUGE-L': one_shot_rouge['rougeL'],\n",
        "        'BERTScore F1': one_shot_bertscore_f1.mean().item()\n",
        "    },\n",
        "    ('Few-shot', model_name): {\n",
        "        'ROUGE-1': few_shot_rouge['rouge1'],\n",
        "        'ROUGE-2': few_shot_rouge['rouge2'],\n",
        "        'ROUGE-L': few_shot_rouge['rougeL'],\n",
        "        'BERTScore F1': few_shot_bertscore_f1.mean().item()\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- Create DataFrame ---\n",
        "\n",
        "df_results = pd.DataFrame.from_dict(results, orient='index')\n",
        "\n",
        "# Set the index names\n",
        "df_results.index.names = ['Prompt Type', 'Model']"
      ],
      "metadata": {
        "id": "UHP74IzM_qBN",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1wYBVPPdQ99o",
      "cell_type": "code",
      "source": [
        "# Display the DataFrame\n",
        "print(df_results)"
      ],
      "metadata": {
        "id": "1wYBVPPdQ99o",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "zV4XDPT2UAwv",
      "cell_type": "code",
      "source": [
        "file_name = \"results.pkl\"\n",
        "file_path = os.path.join(data_path, file_name)\n",
        "\n",
        "try:\n",
        "    df_results.to_pickle(file_path)\n",
        "    print(f\"Successfully saved the DataFrame as pickle to: {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the pickle file: {e}\")"
      ],
      "metadata": {
        "id": "zV4XDPT2UAwv",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}